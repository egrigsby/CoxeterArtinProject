{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI6jpokXJ1zP"
   },
   "source": [
    "# Importing functions from other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 28279,
     "status": "ok",
     "timestamp": 1750355546735,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "HVMLcWABP_UP",
    "outputId": "f5e39971-6de8-49c6-d735-5c602a87e516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in ./myEnv/lib/python3.13/site-packages (0.2)\n",
      "Requirement already satisfied: IPython in ./myEnv/lib/python3.13/site-packages (from import-ipynb) (9.3.0)\n",
      "Requirement already satisfied: nbformat in ./myEnv/lib/python3.13/site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: decorator in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./myEnv/lib/python3.13/site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./myEnv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myEnv/lib/python3.13/site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myEnv/lib/python3.13/site-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./myEnv/lib/python3.13/site-packages (from nbformat->import-ipynb) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./myEnv/lib/python3.13/site-packages (from nbformat->import-ipynb) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./myEnv/lib/python3.13/site-packages (from nbformat->import-ipynb) (5.8.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./myEnv/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./myEnv/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./myEnv/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./myEnv/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./myEnv/lib/python3.13/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myEnv/lib/python3.13/site-packages (from stack_data->IPython->import-ipynb) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myEnv/lib/python3.13/site-packages (from stack_data->IPython->import-ipynb) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myEnv/lib/python3.13/site-packages (from stack_data->IPython->import-ipynb) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1750355547029,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "BrUCHEhZ1TrA"
   },
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45884,
     "status": "ok",
     "timestamp": 1750355592911,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "D1FeoMlzJ46b",
    "outputId": "484c5295-b3cf-4973-cf89-da8667327956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reducing:  s₀s₂s₂s₄\n",
      "After being reduced:  s₀s₄\n",
      "Before reducing:  s₀s₂⁻¹s₂s₄\n",
      "After reducing:  s₀s₄\n"
     ]
    }
   ],
   "source": [
    "#note: Restart Kernel, evertime a change is made on either notebook being imported\n",
    "# running all notebooks locally\n",
    "\n",
    "# coxeter group imports\n",
    "from CheckCoxeter_GenRandomConjugates_GinaRob import subroutine_b_cox, is_coxeter_matrix\n",
    "from GenArtinCoxRelators_NonvisiblyReduced_CelinaRoman import reduce_coxeter_word, reduce_artin_word, cox_gen, cox_rel\n",
    "\n",
    "# artin group imports\n",
    "from CheckCoxeter_GenRandomConjugates_GinaRob import subroutine_b_artin #no is_artin_matrix yet\n",
    "from GenArtinCoxRelators_NonvisiblyReduced_CelinaRoman import reduce_artin_word, artin_gen, artin_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750355815532,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "BBBGGQLoNoD2"
   },
   "outputs": [],
   "source": [
    "#Run this preamble to import some libraries that are available in google colab that are often useful.\n",
    "#Numpy is good for efficiently working with array/vector/matrix data.\n",
    "#Random is good for generating random numbers according to some (discrete or continuous) distribution\n",
    "#Matplotlib is good for plotting\n",
    "#Torch is PyTorch, which is the standard python library for creating and training ML models\n",
    "#You may need to call other libraries for your code\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Additional\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da56h5xuIXOz"
   },
   "source": [
    "# Generating a trivial word using subroutines (Coxeter and Artin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1750355817058,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "S__PoR8pIdry"
   },
   "outputs": [],
   "source": [
    "# Function generating the trivial words\n",
    "def wordElongater(generators, relators, N: int, mode=\"coxeter\") -> List[int]:\n",
    "  \"\"\"\n",
    "  goal: generate a trivial word of length N by making it longer using subroutineB then removing 'aa' relations to make it less visibly reducible\n",
    "  \"\"\"\n",
    "  word_creation_routine = None    #subroutine_b\n",
    "  reduce_visible_routine = None   #subroutine_a\n",
    "\n",
    "  if mode == \"coxeter\":\n",
    "    word_creation_routine = subroutine_b_cox\n",
    "    reduce_visible_routine = reduce_coxeter_word\n",
    "  elif mode == \"artin\":\n",
    "    word_creation_routine = subroutine_b_artin\n",
    "    reduce_visible_routine = reduce_artin_word\n",
    "\n",
    "\n",
    "  #initialize the empty word\n",
    "  tWord = []\n",
    "\n",
    "  # Check edge case where subroutine B wouldn't work (only 1 valid relator that only ever uses 2 generators)\n",
    "  # get at least 2 relators with at least 2 generators \n",
    "  uniqueRels = []\n",
    "  if mode == \"coxeter\":\n",
    "    for rel in relators: \n",
    "      if len(rel) <= 2:  # skip relators that are too short\n",
    "        continue\n",
    "      uniqueGens = set()\n",
    "      for gen in rel: \n",
    "        uniqueGens.add(gen)\n",
    "      if len(uniqueGens) >= 2:\n",
    "        uniqueRels.append(rel)\n",
    "    # check if number of unique relators is less than 2\n",
    "    if len(uniqueRels) == 1:\n",
    "      rel = uniqueRels[0]\n",
    "      if random.random() < 0.5:\n",
    "        rel = rel[::-1]  # reverse the relator with 50% probability\n",
    "      return uniqueRels[0] * (N // len(uniqueRels[0])) \n",
    "    elif len(uniqueRels) == 0:\n",
    "      raise ValueError(\"Not enough valid relators with at least 2 generators to elongate the word.\")\n",
    "  elif mode == \"artin\":\n",
    "    if len(generators) == 1:\n",
    "      raise ValueError(\"Not enough generators to elongate the word.\")\n",
    "\n",
    "\n",
    "  ## Subroutine B: Elongating the word\n",
    "  #run until desired size is reached (tWord will be of length: >= N)\n",
    "  tWord = word_creation_routine(tWord, generators, relators)  #1st pass\n",
    "  while( len(tWord) < N ):\n",
    "    tWord = word_creation_routine(tWord, generators, relators)\n",
    "\n",
    "\n",
    "  ## Subroutine A: removing the 'aa' visible trivial parts of a word\n",
    "  #tWord=subroutineA(tWord)\n",
    "  tWord = reduce_visible_routine(tWord)\n",
    "\n",
    "\n",
    "  #check that it's long enough, if it is then return tWord, if not then call again\n",
    "  if len(tWord) < N:\n",
    "    tWord = wordElongater(generators, relators, N, mode=mode)\n",
    "\n",
    "  return tWord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "IY = math.inf\n",
    "coxeterMatrix = np.array([\n",
    "    [IY, 3, 2, 2],\n",
    "    [3, 1, 3, 2],\n",
    "    [2, 3, 1, 3],\n",
    "    [2, 2, 3, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1750355817319,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "ygsjMzk0qIVh",
    "outputId": "400d42ba-064a-41ec-e5e9-38858c9362d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid Coxeter matrix.\n",
      "[1, 2, 3, 4]\n",
      "[[1, 1], [2, 2], [3, 3], [4, 4], (1, 2, 1, 2, 1, 2), (1, 3, 1, 3), (1, 4, 1, 4), (2, 3, 2, 3, 2, 3), (2, 4, 2, 4), (3, 4, 3, 4, 3, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Validating functions used to get generators and relators from a coxeter matrix:\n",
    "\n",
    "coxeterMatrix = np.array([\n",
    "    [1, 3, 2, 2],\n",
    "    [3, 1, 3, 2],\n",
    "    [2, 3, 1, 3],\n",
    "    [2, 2, 3, 1]\n",
    "])\n",
    "\n",
    "#first check if the matrix is valid:\n",
    "is_coxeter_matrix(4, coxeterMatrix)\n",
    "\n",
    "## Get Generators and Relators\n",
    "cGenerators = cox_gen(coxeterMatrix)\n",
    "cRelators = cox_rel(coxeterMatrix)\n",
    "\n",
    "\n",
    "print(cGenerators)\n",
    "print(cRelators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1750355817623,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "lITO8hyHKP5y",
    "outputId": "9969b52c-abd0-4358-b3ae-a64079fe6273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our word must be greater than or equal to 10\n",
      "Trivial Word: [1, 3, 2, 1, 4, 3, 4, 3, 4, 3, 1, 2, 3, 1]\n",
      "Length of Word: 14\n"
     ]
    }
   ],
   "source": [
    "# Validating subroutine functions and the trivial word generator function:\n",
    "\n",
    "N = 10\n",
    "trivialWord = wordElongater(cGenerators, cRelators, N)\n",
    "print(f\"Our word must be greater than or equal to {N}\")\n",
    "print(f\"Trivial Word: {trivialWord}\")\n",
    "print(f\"Length of Word: {len(trivialWord)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3xXuu2oITbK"
   },
   "source": [
    "## Debug tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1750355818229,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "O870UPkARuU2",
    "outputId": "717c9272-a7e4-4ad0-f4f1-44dd125ec135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our word must be greater than or equal to 10\n",
      "Trivial Word: [3, 2, 4, 3, 1, 3, 4, 3, 4, 3, 4, 1, 3, 4, 2, 3]\n",
      "Length of Word: 16\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "trivialWord = wordElongater(cGenerators, cRelators, N)\n",
    "print(f\"Our word must be greater than or equal to {N}\")\n",
    "print(f\"Trivial Word: {trivialWord}\")\n",
    "print(f\"Length of Word: {len(trivialWord)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1750355818580,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "J06VQLmTb06y",
    "outputId": "60a51e0d-333e-4f36-96d3-58041f6daf86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 'h', 'i', 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "la = [1,1,1,2,2,2]\n",
    "t = ['h', 'i']\n",
    "#insert elm into the list\n",
    "la[3:3] = t\n",
    "print(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750355818782,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "NuPL4szwh7WF",
    "outputId": "c7f69543-a6d9-48d2-fdc8-744b605b6969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 6, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "a1 = [1,2,3]\n",
    "a2 = [6,5,4]\n",
    "a3 = a1 + a2\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hvzKFhoKZva"
   },
   "source": [
    "# Generating Trivial Word Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750355819966,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "tNAeSDtJKe5o"
   },
   "outputs": [],
   "source": [
    "def writeRawTrivialDataset(generators, relators, totalWords, targetSize, mode=\"coxeter\"):\n",
    "  f = open(\"trivialWords.txt\", mode=\"w\")\n",
    "  words = []\n",
    "  for i in range(totalWords):\n",
    "    word_as_list = wordElongater(generators, relators, targetSize, mode=mode)\n",
    "    f.write(\" \".join(str(item) for item in word_as_list) + \"\\n\")\n",
    "    words.append(word_as_list)\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1750355820392,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "vjAGMzJtbvGV",
    "outputId": "ba38b0db-e02b-4691-8b4f-10a6c65ecb54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid Coxeter matrix.\n"
     ]
    }
   ],
   "source": [
    "# write to a file, trivialWords.txt\n",
    "\n",
    "totalWords = 100\n",
    "coxeterMatrix = np.array([\n",
    "    [1, 3, 2, 2],\n",
    "    [3, 1, 3, 2],\n",
    "    [2, 3, 1, 3],\n",
    "    [2, 2, 3, 1]\n",
    "])\n",
    "#first check if the matrix is valid:\n",
    "is_coxeter_matrix(4, coxeterMatrix)\n",
    "\n",
    "## Get Generators and Relators\n",
    "cGenerators = cox_gen(coxeterMatrix)\n",
    "cRelators = cox_rel(coxeterMatrix)\n",
    "\n",
    "targetSize = 16\n",
    "\n",
    "dataset = writeRawTrivialDataset(cGenerators, cRelators, totalWords, targetSize, mode=\"coxeter\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1750355821098,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "GZyq0w2RcG8w",
    "outputId": "6d4189ce-aa98-422b-a62a-8a68a52fee24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "[[1, 2, 1, -2, -1, -2], [1, 3, -3, -1], [1, 4, -4, -1], [2, 3, 2, -3, -2, -3], [2, 4, -4, -2], [3, 4, 3, -4, -3, -4]]\n"
     ]
    }
   ],
   "source": [
    "aGenerators = artin_gen(coxeterMatrix)\n",
    "aRelators = artin_rel(coxeterMatrix)\n",
    "print(aGenerators)\n",
    "print(aRelators)\n",
    "totalWords = 100\n",
    "targetSize = 20\n",
    "dataset = writeRawTrivialDataset(aGenerators, aRelators, totalWords, targetSize, mode=\"artin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxU6Pl9A0ovH"
   },
   "source": [
    "# Get a distribution of trivial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750355822240,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "fw3VdKKR2mHi"
   },
   "outputs": [],
   "source": [
    "# Read in dataset from file\n",
    "\n",
    "def readDataset(fileName:str):\n",
    "  words = []\n",
    "  with open(fileName) as fileObj:\n",
    "    for line in fileObj:\n",
    "      raw_list = line.split(\" \")   #note: last gen has \\n char as well\n",
    "      gen_list = list(map(int, raw_list))\n",
    "      lenWord = len(gen_list)\n",
    "      words.append(gen_list)\n",
    "  return words\n",
    "\n",
    "# Use dataset to get a list of tuples with word length types and their frequencies\n",
    "\n",
    "def getWordLengthFrequencies(dataset) -> List[Tuple[int,int]]:\n",
    "  frequencies = {}\n",
    "  for word in dataset:\n",
    "    wordLen = len(word)\n",
    "    if wordLen in frequencies:\n",
    "      frequencies[wordLen] += 1\n",
    "    else:\n",
    "      frequencies[wordLen] = 1\n",
    "  return frequencies\n",
    "\n",
    "# Create a plot for the frequencies dictionary\n",
    "\n",
    "def plotFrequencies(dataset):\n",
    "  #turn dataset into list of lengths\n",
    "  wordLengths = [len(word) for word in dataset]\n",
    "\n",
    "  plt.hist(wordLengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1750355845801,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "PgViV5Nq6wIV",
    "outputId": "d1e7f7a8-33d9-4069-8ba9-6fa9cfe78dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "[[1, 2, 1, -2, -1, -2], [1, 3, -3, -1], [1, 4, -4, -1], [2, 3, 2, -3, -2, -3], [2, 4, -4, -2], [3, 4, 3, -4, -3, -4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the above functions:\n",
    "aGenerators = artin_gen(coxeterMatrix)\n",
    "aRelators = artin_rel(coxeterMatrix)\n",
    "print(aGenerators)\n",
    "print(aRelators)\n",
    "totalWords = 100\n",
    "targetSize = 20\n",
    "words = writeRawTrivialDataset(aGenerators, aRelators, totalWords, targetSize, mode=\"artin\")\n",
    "#words = readDataset(\"trivialWords.txt\")\n",
    "\n",
    "plotFrequencies(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v10HdYfV6whl"
   },
   "source": [
    "## Debugs testing dataset and freq functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1750354584523,
     "user": {
      "displayName": "David Ruiz De Castilla",
      "userId": "02610518650987828633"
     },
     "user_tz": 240
    },
    "id": "PlBHIZzr2YfS",
    "outputId": "e2258921-40e7-4eab-d339-ebe1cb98a56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Word: [3, 1, -3, 2, 1, 3, 4, 1, 3, 3, 2, 3, -2, -3, -2, -3, -1, -4, -3, -1, -2, 3, -1, -3]\n",
      "Word Lengths: dict_keys([24, 20, 22, 26])\n",
      "Total Words: 100\n"
     ]
    }
   ],
   "source": [
    "# Debugging code:\n",
    "\n",
    "trivialDataset = readDataset(fileName=\"trivialWords.txt\")\n",
    "print(f\"First Word: {dataset[0]}\")\n",
    "\n",
    "frequencies = getWordLengthFrequencies(dataset)\n",
    "print(f\"Word Lengths: {frequencies.keys()}\")  \n",
    "\n",
    "total = 0\n",
    "for freq in frequencies.values():\n",
    "  total += freq\n",
    "print(f\"Total Words: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM5h2FmIZXYF"
   },
   "source": [
    "# Match Trivial Dataset with a \"likely\" Non-Trivial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a trivial dataset and set of generators to return a similarly sized non trivial dataset\n",
    "\n",
    "def writeRawNontrivialDataset(trivialDataset, generators, fileName=\"nontrivialWords.txt\"):\n",
    "\n",
    "  nontrivialDataset = []\n",
    "\n",
    "  # create matchine likely non trivial word based on length of each trivial word it reads in a loop \n",
    "  for trivialWord in trivialDataset: \n",
    "    \n",
    "    nontrivialWord = []\n",
    "    for i in range(len(trivialWord)):\n",
    "      randomGen = generators[random.randint(0, len(generators)-1)]\n",
    "      nontrivialWord.append(randomGen)\n",
    "    nontrivialDataset.append(nontrivialWord)\n",
    "\n",
    "  # add the words to the nonTrivialWords.txt file (todo: in a random order)\n",
    "  f = open(\"nontrivialWords.txt\", mode=\"w\")\n",
    "  words = []\n",
    "  for word_as_list in nontrivialDataset:\n",
    "    f.write(\" \".join(str(item) for item in word_as_list) + \"\\n\")\n",
    "    words.append(word_as_list)\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontrivialDataset = writeRawNontrivialDataset(trivialDataset, aGenerators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the dataet file, at end the line use ,1 if nontrivial and ,0 if trivial\n",
    "#include date for when the file was generated \n",
    "#create folders for type of dataset being made?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both datasets into one label per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def createTrainTestSplitData(trivialFileName, nontrivialFileName, test_size=0.3):\n",
    "    \"\"\"\n",
    "    returns (trainDF, testDF) \n",
    "    \"\"\"\n",
    "    # Step 1: Read the raw data \n",
    "    def loadRaw(filename, label):\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        # Each line is a list of tokens separated by spaces\n",
    "        return pd.DataFrame({\n",
    "            'tokens': [line.strip().split() for line in lines],\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "    # Load data from both classes\n",
    "    raw_tDF = loadRaw(trivialFileName, '0') #raw trivial dataframe\n",
    "    raw_ntDF = loadRaw(nontrivialFileName, '1') #raw non-trivial dataframe\n",
    "\n",
    "    # combines both raw datasets into a single pandas dataframe\n",
    "    raw_df = pd.concat([raw_tDF, raw_ntDF]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # creating 2 separate training and testing dataframes (modify test_size param)\n",
    "    train_df, test_df = train_test_split(raw_df, test_size=test_size, random_state=42, stratify=raw_df['label'])\n",
    "\n",
    "    # Optional: print or save\n",
    "    print(\"Training set size:\", len(train_df))\n",
    "    print(\"Testing set size:\", len(test_df))\n",
    "\n",
    "    # Save to CSV or use directly\n",
    "    train_df.to_csv('train.csv', index=False)\n",
    "    test_df.to_csv('test.csv', index=False)\n",
    "    \n",
    "    return (train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 140\n",
      "Testing set size: 60\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = createTrainTestSplitData(\"trivialWords.txt\", \"nontrivialWords.txt\", test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Function to load existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return dataframe representing the dataset\n",
    "def loadDataset(datasetName:str):\n",
    "    df = pd.read_csv(datasetName)  # ex: 'train.csv' or 'test.csv'\n",
    "\n",
    "    # Convert the 'tokens' column back to lists\n",
    "    df['tokens'] = df['tokens'].apply(ast.literal_eval)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  label\n",
      "0  [4, 2, 3, 1, 2, 3, 2, 3, 2, 3, 1, 4, 3, 2, 3, ...      0\n",
      "1  [2, 2, 1, 1, 3, 1, 1, 1, 1, 3, 4, 2, 2, 1, 1, ...      1\n",
      "2  [4, 2, 3, 3, 3, 1, 1, 4, 2, 3, 2, 3, 3, 2, 1, ...      1\n",
      "3  [2, 1, 2, 3, 2, 1, 3, 1, 3, 4, 4, 2, 3, 1, 3, ...      1\n",
      "4  [4, 4, 1, 2, 4, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, ...      1\n",
      "\n",
      "Word as a list of tokens: ['4', '2', '3', '1', '2', '3', '2', '3', '2', '3', '1', '4', '3', '2', '3', '2', '3', '2', '4', '3', '1', '2', '1', '2', '1', '4']\n",
      "Label for Entry 1: 0\n"
     ]
    }
   ],
   "source": [
    "trainDF = loadDataset(\"train.csv\")\n",
    "testDF = loadDataset('test.csv')\n",
    "print(trainDF.head())\n",
    "print()\n",
    "print(f\"Word as a list of tokens: {trainDF['tokens'][0]}\") # prints the token list of the first example\n",
    "print(f\"Label for Entry 1: {trainDF['label'][0]}\")  # print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single function to make csv datasets and dataframes for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMeMyData(coxeterMatrix, datasetSize, wordLength, test_size=\"0.3\", mode=\"coxeter\"):\n",
    "    \"\"\" \n",
    "    returns (trainDF, testDF)\n",
    "    \"\"\"\n",
    "    generators = None  \n",
    "    relators = None\n",
    "    datasetSize = datasetSize // 2 \n",
    "    if mode == \"coxeter\":\n",
    "        is_coxeter_matrix(len(coxeterMatrix), coxeterMatrix)\n",
    "        generators = cox_gen(coxeterMatrix)\n",
    "        relators = cox_rel(coxeterMatrix)\n",
    "    elif mode == \"artin\":\n",
    "        print(\"check again\")\n",
    "        generators = artin_gen(coxeterMatrix)\n",
    "        relators = artin_rel(coxeterMatrix)\n",
    "    \n",
    "    # create nontrivialwords.txt and trivialwords.txt \n",
    "    trivialDataset = writeRawTrivialDataset(generators, relators, datasetSize, wordLength, mode=mode)\n",
    "    nontrivialDataset = writeRawNontrivialDataset(trivialDataset, generators)\n",
    "    \n",
    "    trainDF, testDF = createTrainTestSplitData(\"trivialWords.txt\", \"nontrivialWords.txt\")\n",
    "    \n",
    "    return trainDF, testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid Coxeter matrix.\n",
      "Training set size: 1400\n",
      "Testing set size: 600\n"
     ]
    }
   ],
   "source": [
    "coxeterMatrix = np.array([\n",
    "    [1, 3, 2, 2],\n",
    "    [3, 1, 3, 2],\n",
    "    [2, 3, 1, 3],\n",
    "    [2, 2, 3, 1]\n",
    "])\n",
    "\n",
    "trainDF, testDF = makeMeMyData(coxeterMatrix, 2000, 20, test_size=0.3, mode=\"coxeter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file io libraries\n",
    "import os \n",
    "# save dataset to a file in the generatedData folder\n",
    "def saveDatasetToFile(trainDF, testDF, folderName=\"generatedData\"):\n",
    "    if not os.path.exists(folderName):\n",
    "        os.makedirs(folderName)\n",
    "    \n",
    "    trainFilePath = os.path.join(folderName, \"train.csv\")\n",
    "    testFilePath = os.path.join(folderName, \"test.csv\")\n",
    "    \n",
    "    trainDF.to_csv(trainFilePath, index=False)\n",
    "    testDF.to_csv(testFilePath, index=False)\n",
    "    \n",
    "    print(f\"Train dataset saved to {trainFilePath}\")\n",
    "    print(f\"Test dataset saved to {testFilePath}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1014Ut8DfOnDOnkl--ntZ4MgQL8fcEf6l",
     "timestamp": 1750101219903
    }
   ]
  },
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
